Developed a data engineering solution utilizing Azure Databricks, Azure Data Lake Gen2, Azure Data Factory, and Power BI. Key methods included:
  + Architecture Design: Built a solution architecture integrating Azure Databricks with Azure Data Lake Gen2 and Data Factory, and visualized outputs with Power BI.
  + Databricks Utilization: Configured and managed Databricks clusters, jobs, and mounts using secrets from Azure Key Vault. Created and executed Databricks notebooks and workflows.
  + Data Processing: Leveraged PySpark and Spark SQL for data ingestion, transformations, and creating views. Implemented full refresh and incremental load patterns with Delta Lake.
  + Delta Lake Implementation: Utilized Delta Lake for Lakehouse architecture, performing operations such as Read, Write, Update, Delete, and Merge. Implemented incremental load and managed data versioning.
  + Unity Catalog: Implemented Unity Catalog for data governance, creating and managing Metastore, configuring external data lakes, and leveraging capabilities like Data Discovery and Access Control.
  + Pipeline Management: Designed and scheduled ADF pipelines to execute Databricks notebooks, handling dependencies and monitoring for robust data processing.



